{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# BMI Prediction Using BRFSS Data\n",
        "\n",
        "This notebook implements the complete pipeline for BMI prediction using the Behavioral Risk Factor Surveillance System (BRFSS) 2024 dataset, which is not included in this repo. The link to download this dataset is below:\n",
        "\n",
        "https://www.cdc.gov/brfss/annual_data/annual_2024.html\n",
        "\n",
        "James Simon (Project Conceptualization, Literature Review, Paper, Fairness, Feature Selection)\n",
        "Shashank Joshi (Project Conceptualization, Model Training and Evaluation, Feature Selection, Paper)\n",
        "Emma Yue (Graphs, Presentation, Data Pre-Processing, Risk Estimates)\n",
        "Phani Yalamanchili (Presentation, Flowcharts, Feature Selection, Data Pre-Processing)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 1: Imports & Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestRegressor,\n",
        "    GradientBoostingRegressor,\n",
        "    VotingRegressor,\n",
        "    StackingRegressor\n",
        ")\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import (\n",
        "    mean_absolute_error,\n",
        "    mean_squared_error,\n",
        "    r2_score,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score,\n",
        "    brier_score_loss,\n",
        "    confusion_matrix,\n",
        "    classification_report\n",
        ")\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "np.random.seed(42)\n",
        "plt.style.use('seaborn-v0_8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# WHO/CDC standards\n",
        "BMI_CATEGORIES = [\n",
        "    'Underweight',\n",
        "    'Normal',\n",
        "    'Overweight',\n",
        "    'Obese Class I',\n",
        "    'Obese Class II',\n",
        "    'Obese Class III'\n",
        "]\n",
        "\n",
        "# For graphs\n",
        "CATEGORY_COLORS = [\n",
        "    '#210c52',  # Underweight\n",
        "    '#a88de6',  # Normal\n",
        "    '#d0c2f5',  # Overweight\n",
        "    '#7a4ec7',  # Obese Class I\n",
        "    '#5d33ab',  # Obese Class II\n",
        "    '#3c1e7f'   # Obese Class III \n",
        "]\n",
        "\n",
        "# 16 Selected Features (populated after feature selection)\n",
        "FEATURE_COLS = [\n",
        "    'GENHLTH', '_AGEG5YR', 'DIABETE4', '_SEX', 'EMPLOY1', 'SDHFOOD1',\n",
        "    '_INCOMG1', '_AGE65YR', '_RACE', 'HAVARTH4', '_AGE_G', 'CHILDREN',\n",
        "    'ALCDAY4', 'EXERANY2', '_TOTINDA', 'MENTHLTH'\n",
        "]\n",
        "\n",
        "# Feature descriptions for output tables\n",
        "FEATURE_NAMES = {\n",
        "    '_AGEG5YR': 'Age Group (5-year)',\n",
        "    'GENHLTH': 'General Health',\n",
        "    'MENTHLTH': 'Mental Health Days',\n",
        "    'DIABETE4': 'Diabetes Status',\n",
        "    '_INCOMG1': 'Income Group',\n",
        "    'EMPLOY1': 'Employment Status',\n",
        "    'ALCDAY4': 'Alcohol Consumption',\n",
        "    '_AGE_G': 'Age Detailed',\n",
        "    '_RACE': 'Race/Ethnicity',\n",
        "    '_AGE65YR': 'Age 65+',\n",
        "    'SDHFOOD1': 'Food Security',\n",
        "    'CHILDREN': 'Number of Children',\n",
        "    'HAVARTH4': 'Arthritis',\n",
        "    '_SEX': 'Biological Sex',\n",
        "    'EXERANY2': 'Any Exercise',\n",
        "    '_TOTINDA': 'Physical Activity Index'\n",
        "}\n",
        "\n",
        "# File paths\n",
        "BASE_DIR = Path('.')  \n",
        "DATA_DIR = Path('..') / 'data' \n",
        "FIGURE_DIR = BASE_DIR / 'figures'\n",
        "OUTPUT_DIR = BASE_DIR / 'outputs'\n",
        "FEATURE_DIR = BASE_DIR / 'feature_selection_results'\n",
        "ORIGINAL_DATA_PATH = DATA_DIR / 'LLCP2024.csv'\n",
        "BALANCED_44K_PATH = DATA_DIR / 'brfss_balanced_RANDOM.csv'\n",
        "BALANCED_100K_PATH = DATA_DIR / 'brfss_balanced_bmi6_100k (2) (1).csv'\n",
        "FIGURE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "FEATURE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Apply color palette to matplotlib and seaborn\n",
        "sns.set_palette(CATEGORY_COLORS)\n",
        "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=CATEGORY_COLORS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def bmi_to_category(bmi):\n",
        "\n",
        "    if pd.isna(bmi):\n",
        "        return None\n",
        "    \n",
        "    thresholds = [\n",
        "        (18.5, 'Underweight'),\n",
        "        (25, 'Normal'),\n",
        "        (30, 'Overweight'),\n",
        "        (35, 'Obese Class I'),\n",
        "        (40, 'Obese Class II'),\n",
        "        (100, 'Obese Class III')\n",
        "    ]\n",
        "    \n",
        "    for threshold, category in thresholds:\n",
        "        if bmi < threshold:\n",
        "            return category\n",
        "    \n",
        "    return 'Obese Class III'\n",
        "\n",
        "\n",
        "def get_bmi_category_numeric(bmi):\n",
        "\n",
        "    if bmi < 18.5:\n",
        "        return 1  # Underweight\n",
        "    elif bmi < 25:\n",
        "        return 2  # Normal\n",
        "    elif bmi < 30:\n",
        "        return 3  # Overweight\n",
        "    elif bmi < 35:\n",
        "        return 4  # Obese Class I\n",
        "    elif bmi < 40:\n",
        "        return 5  # Obese Class II\n",
        "    else:\n",
        "        return 6  # Obese Class III\n",
        "\n",
        "\n",
        "def print_category_dist(category_counts, total, title=\"Category Distribution\"):\n",
        "\n",
        "    print(f\"\\n{title}:\")\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"{'Category':<20} {'Count':>15} {'Percentage':>15}\")\n",
        "    print(\"-\" * 60)\n",
        "    \n",
        "    for cat in BMI_CATEGORIES:\n",
        "        count = category_counts.get(cat, 0) if isinstance(category_counts, dict) else category_counts.get(cat, 0)\n",
        "        pct = (count / total * 100) if total > 0 else 0\n",
        "        print(f\"{cat:<20} {count:>15,} {pct:>14.2f}%\")\n",
        "    \n",
        "    print(\"-\" * 60)\n",
        "    print(f\"{'Total':<20} {total:>15,} {100.00:>14.2f}%\")\n",
        "\n",
        "\n",
        "def save_figure(fig, filename, dpi=300, bbox_inches='tight'):\n",
        "\n",
        "    filepath = FIGURE_DIR / filename\n",
        "    fig.savefig(filepath, dpi=dpi, bbox_inches=bbox_inches)\n",
        "    print(f\"Saved: {filepath}\")\n",
        "\n",
        "\n",
        "def get_colors(n_colors=5):\n",
        "\n",
        "    if n_colors <= len(CATEGORY_COLORS):\n",
        "        return CATEGORY_COLORS[:n_colors]\n",
        "    else:\n",
        "        return [CATEGORY_COLORS[i % len(CATEGORY_COLORS)] for i in range(n_colors)]\n",
        "\n",
        "\n",
        "def create_category_table(category_counts, total):\n",
        "\n",
        "    bmi_ranges = [\n",
        "        'BMI < 18.5',\n",
        "        '18.5 ≤ BMI < 25',\n",
        "        '25 ≤ BMI < 30',\n",
        "        '30 ≤ BMI < 35',\n",
        "        '35 ≤ BMI < 40',\n",
        "        'BMI ≥ 40'\n",
        "    ]\n",
        "    \n",
        "    data = []\n",
        "    for cat, bmi_range in zip(BMI_CATEGORIES, bmi_ranges):\n",
        "        count = category_counts.get(cat, 0) if isinstance(category_counts, dict) else category_counts.get(cat, 0)\n",
        "        pct = (count / total * 100) if total > 0 else 0\n",
        "        data.append({\n",
        "            'Category': cat,\n",
        "            'BMI Range': bmi_range,\n",
        "            'Count': count,\n",
        "            'Percentage': f\"{pct:.2f}%\"\n",
        "        })\n",
        "    \n",
        "    return pd.DataFrame(data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 2: Data Loading & Preprocessing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = pd.read_csv(ORIGINAL_DATA_PATH)\n",
        "\n",
        "# Convert _BMI5 to BMI since BRFSS stores as integer: 2500 = 25.00\n",
        "bmi_raw = pd.to_numeric(data['_BMI5'], errors='coerce')\n",
        "\n",
        "# Check if BMI is stored as integer or already as decimal\n",
        "if bmi_raw.dropna().max() > 100:\n",
        "    data['BMI'] = bmi_raw.replace({9999: np.nan}) / 100.0\n",
        "else:\n",
        "    data['BMI'] = bmi_raw\n",
        "\n",
        "# Filter invalid BMI values\n",
        "data['BMI'] = data['BMI'].mask((data['BMI'] < 12.0) | (data['BMI'] >= 100.0))\n",
        "data_valid = data[data['BMI'].notna()].copy()\n",
        "\n",
        "print(f\"Valid samples: {len(data_valid):,} (removed {len(data) - len(data_valid):,} invalid/missing)\")\n",
        "print(f\"   Mean: {data_valid['BMI'].mean():.2f}\")\n",
        "print(f\"   Median: {data_valid['BMI'].median():.2f}\")\n",
        "print(f\"   Std: {data_valid['BMI'].std():.2f}\")\n",
        "print(f\"   Range: [{data_valid['BMI'].min():.2f}, {data_valid['BMI'].max():.2f}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_valid['BMI_Category'] = data_valid['BMI'].apply(bmi_to_category)\n",
        "category_counts = data_valid['BMI_Category'].value_counts()\n",
        "\n",
        "# Sort by category order \n",
        "category_counts_ordered = pd.Series({\n",
        "    cat: category_counts.get(cat, 0) \n",
        "    for cat in BMI_CATEGORIES\n",
        "})\n",
        "\n",
        "print_category_dist(category_counts_ordered, len(data_valid), \"Original BMI Category Distribution\")\n",
        "imbalance_ratio = category_counts_ordered.max() / category_counts_ordered.min()\n",
        "print(f\"\\nImbalance ratio: {imbalance_ratio:.2f}x (largest category is {imbalance_ratio:.2f}x the smallest)\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "table_df = create_category_table(category_counts_ordered, len(data_valid))\n",
        "table_path = OUTPUT_DIR / 'table1_bmi_category_distribution.csv'\n",
        "table_df.to_csv(table_path, index=False)\n",
        "\n",
        "print(f\"\\nTable saved to: {table_path}\")\n",
        "print(\"\\nBMI Category Distribution\")\n",
        "print(\"=\" * 80)\n",
        "print(table_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "counts_ordered = [category_counts_ordered.get(cat, 0) for cat in BMI_CATEGORIES]\n",
        "pcts_ordered = [(c / len(data_valid) * 100) for c in counts_ordered]\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Bar chart\n",
        "ax1 = axes[0]\n",
        "bars = ax1.bar(BMI_CATEGORIES, counts_ordered, color=CATEGORY_COLORS, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
        "ax1.set_xlabel('BMI Category', fontweight='bold', fontsize=12)\n",
        "ax1.set_ylabel('Number of Samples', fontweight='bold', fontsize=12)\n",
        "ax1.set_title('Original BMI Category Distribution', fontweight='bold', fontsize=14)\n",
        "ax1.set_xticklabels(BMI_CATEGORIES, rotation=45, ha='right')\n",
        "ax1.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Add value labels on bars\n",
        "for bar, count, pct in zip(bars, counts_ordered, pcts_ordered):\n",
        "    ax1.text(bar.get_x() + bar.get_width()/2., bar.get_height(),\n",
        "             f'{count:,}\\n({pct:.1f}%)', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
        "\n",
        "# Pie chart\n",
        "ax2 = axes[1]\n",
        "wedges, texts, autotexts = ax2.pie(\n",
        "    pcts_ordered, \n",
        "    labels=BMI_CATEGORIES, \n",
        "    colors=CATEGORY_COLORS,\n",
        "    autopct='%1.1f%%', \n",
        "    startangle=90, \n",
        "    textprops={'fontsize': 10}\n",
        ")\n",
        "ax2.set_title('BMI Category Distribution (%)', fontweight='bold', fontsize=14)\n",
        "\n",
        "for autotext in autotexts:\n",
        "    autotext.set_color('white')\n",
        "    autotext.set_fontweight('bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "save_figure(fig, 'original_bmi_category_distribution.png', dpi=300)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 3: Dataset Configurations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find minimum available samples per category \n",
        "available_samples = {cat: len(data_valid[data_valid['BMI_Category'] == cat]) for cat in BMI_CATEGORIES}\n",
        "target_per_category = min(available_samples.values())\n",
        "\n",
        "print(f\"\\nAvailable samples per category:\")\n",
        "for cat, count in available_samples.items():\n",
        "    print(f\"  {cat:<20}: {count:,}\")\n",
        "print(f\"\\nTarget per category: {target_per_category:,} (matching smallest: Underweight)\")\n",
        "\n",
        "# Sample equal amounts from each category\n",
        "balanced_samples_44k = []\n",
        "for cat in BMI_CATEGORIES:\n",
        "    cat_data = data_valid[data_valid['BMI_Category'] == cat].sample(n=target_per_category, random_state=42)\n",
        "    balanced_samples_44k.append(cat_data)\n",
        "\n",
        "# Combine and shuffle\n",
        "data_balanced_44k = pd.concat(balanced_samples_44k, ignore_index=True)\n",
        "data_balanced_44k = data_balanced_44k.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "print(f\"\\nBalanced 44K dataset created: {len(data_balanced_44k):,} samples\")\n",
        "print_category_dist(data_balanced_44k['BMI_Category'].value_counts(), len(data_balanced_44k), \"Balanced 44K Distribution\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the pre-balanced 100K dataset\n",
        "data_balanced_100k = pd.read_csv(BALANCED_100K_PATH)\n",
        "if 'BMI_Category' not in data_balanced_100k.columns:\n",
        "    data_balanced_100k['BMI_Category'] = data_balanced_100k['BMI'].apply(bmi_to_category)\n",
        "\n",
        "print(f\"Loaded 100K dataset: {len(data_balanced_100k):,} samples\")\n",
        "print_category_dist(data_balanced_100k['BMI_Category'].value_counts(), len(data_balanced_100k), \"100K Dataset Distribution\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_dataset_for_training(df, dataset_name, feature_cols):\n",
        "    print(f\"\\nPreparing {dataset_name}...\")\n",
        "    \n",
        "    available_features = [f for f in feature_cols if f in df.columns]\n",
        "    missing_features = [f for f in feature_cols if f not in df.columns]\n",
        "    \n",
        "    if missing_features:\n",
        "        print(f\"Missing features: {missing_features}\")\n",
        "    \n",
        "    X = df[available_features].copy()\n",
        "    y = df['BMI'].copy()\n",
        "    \n",
        "    # Handle missing values with median imputation\n",
        "    imputer = SimpleImputer(strategy='median')\n",
        "    X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns, index=X.index)\n",
        "    \n",
        "    # Stratified split by BMI category\n",
        "    y_cat = y.apply(get_bmi_category_numeric)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_imputed, y, test_size=0.2, random_state=42, stratify=y_cat\n",
        "    )\n",
        "    \n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
        "    X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
        "    \n",
        "    print(f\"  Train: {len(X_train):,}, Test: {len(X_test):,}\")\n",
        "    \n",
        "    return {\n",
        "        'name': dataset_name,\n",
        "        'X_train': X_train_scaled,\n",
        "        'X_test': X_test_scaled,\n",
        "        'y_train': y_train,\n",
        "        'y_test': y_test,\n",
        "        'df': df,\n",
        "        'features': available_features\n",
        "    }\n",
        "\n",
        "datasets = {}\n",
        "\n",
        "# 1. Original (use data_valid from Section 2)\n",
        "datasets['Original (414K)'] = prepare_dataset_for_training(data_valid, 'Original (414K)', FEATURE_COLS)\n",
        "\n",
        "# 2. Balanced 44K\n",
        "datasets['Balanced Fully (44K)'] = prepare_dataset_for_training(data_balanced_44k, 'Balanced Fully (44K)', FEATURE_COLS)\n",
        "\n",
        "# 3. Even BMI Categories (100K)\n",
        "datasets['Even BMI Categories (100K)'] = prepare_dataset_for_training(data_balanced_100k, 'Even BMI Categories (100K)', FEATURE_COLS)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_and_evaluate_stacking(dataset_dict):\n",
        "    name = dataset_dict['name']\n",
        "    X_train = dataset_dict['X_train']\n",
        "    X_test = dataset_dict['X_test']\n",
        "    y_train = dataset_dict['y_train']\n",
        "    y_test = dataset_dict['y_test']\n",
        "    \n",
        "    stacking = StackingRegressor(\n",
        "        estimators=[\n",
        "            ('ridge', Ridge(alpha=0.1, random_state=42)),\n",
        "            ('rf', RandomForestRegressor(n_estimators=100, max_depth=15, random_state=42, n_jobs=-1)),\n",
        "            ('gb', GradientBoostingRegressor(n_estimators=100, learning_rate=0.08, max_depth=10, random_state=42))\n",
        "        ],\n",
        "        final_estimator=Ridge(alpha=0.1),\n",
        "        cv=3,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    \n",
        "    stacking.fit(X_train, y_train)\n",
        "    y_pred = stacking.predict(X_test)\n",
        "    \n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    \n",
        "    print(f\"  RMSE: {rmse:.2f}, MAE: {mae:.2f}, R²: {r2:.4f}\")\n",
        "    \n",
        "    return {\n",
        "        'name': name,\n",
        "        'model': stacking,\n",
        "        'y_pred': y_pred,\n",
        "        'y_test': y_test,\n",
        "        'rmse': rmse,\n",
        "        'mae': mae,\n",
        "        'r2': r2\n",
        "    }\n",
        "\n",
        "results = {}\n",
        "for ds_name, ds_dict in datasets.items():\n",
        "    results[ds_name] = train_and_evaluate_stacking(ds_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DEMOGRAPHIC_FEATURES = {\n",
        "    '_RACE': {'name': 'Race/Ethnicity', 'labels': {1: 'White', 2: 'Black', 3: 'Native Am', 4: 'Asian',\n",
        "               5: 'Pacific', 6: 'Other', 7: 'Multiracial', 8: 'Hispanic'}},\n",
        "    '_SEX': {'name': 'Sex', 'labels': {1: 'Male', 2: 'Female'}},\n",
        "    '_INCOMG1': {'name': 'Income Level', 'labels': {1: '<$15K', 2: '$15-25K', 3: '$25-35K', 4: '$35-50K',\n",
        "                   5: '$50-100K', 6: '$100-200K', 7: '>$200K'}},\n",
        "    '_AGEG5YR': {'name': 'Age Group', 'labels': {1: '18-24', 2: '25-29', 3: '30-34', 4: '35-39', 5: '40-44',\n",
        "                   6: '45-49', 7: '50-54', 8: '55-59', 9: '60-64', 10: '65-69', 11: '70-74', 12: '75-79', 13: '80+'}}\n",
        "}\n",
        "\n",
        "def calculate_disparity(y_true, y_pred, demo_values):\n",
        "    unique_groups = [g for g in np.unique(demo_values) if pd.notna(g)]\n",
        "    \n",
        "    if len(unique_groups) < 2:\n",
        "        return 0\n",
        "    \n",
        "    group_maes = []\n",
        "    for group in unique_groups:\n",
        "        mask = demo_values == group\n",
        "        if mask.sum() >= 10: \n",
        "            group_mae = mean_absolute_error(np.array(y_true)[mask], np.array(y_pred)[mask])\n",
        "            group_maes.append(group_mae)\n",
        "    \n",
        "    if len(group_maes) < 2:\n",
        "        return 0\n",
        "    \n",
        "    return max(group_maes) - min(group_maes)\n",
        "\n",
        "def calculate_avg_disparity(dataset_dict, result):\n",
        "    df = dataset_dict['df']\n",
        "    y_test = result['y_test']\n",
        "    y_pred = result['y_pred']\n",
        "    \n",
        "    # Get test indices\n",
        "    test_idx = y_test.index\n",
        "    \n",
        "    disparities = []\n",
        "    for feat in DEMOGRAPHIC_FEATURES.keys():\n",
        "        if feat in df.columns:\n",
        "            demo_values = df.loc[test_idx, feat].values\n",
        "            disparity = calculate_disparity(y_test.values, y_pred, demo_values)\n",
        "            if disparity > 0:\n",
        "                disparities.append(disparity)\n",
        "    \n",
        "    return np.mean(disparities) if disparities else 0\n",
        "\n",
        "# Calculate disparity for each dataset\n",
        "for ds_name in datasets.keys():\n",
        "    avg_disp = calculate_avg_disparity(datasets[ds_name], results[ds_name])\n",
        "    results[ds_name]['avg_disparity'] = avg_disp\n",
        "    print(f\"{ds_name}: Avg Disparity = {avg_disp:.2f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "comparison_data = []\n",
        "for ds_name, result in results.items():\n",
        "    comparison_data.append({\n",
        "        'Dataset': ds_name,\n",
        "        'Samples': len(datasets[ds_name]['df']),\n",
        "        'MAE': result['mae'],\n",
        "        'R²': result['r2'],\n",
        "        'Avg Disparity': result['avg_disparity']\n",
        "    })\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 100)\n",
        "print(\"TABLE 2: DATASET COMPARISON (Using Stacking Ensemble)\")\n",
        "print(\"=\" * 100)\n",
        "print(f\"\\n{'Dataset':<30} {'Samples':>12} {'MAE':>10} {'R²':>10} {'Avg Disparity':>15}\")\n",
        "print(\"-\" * 100)\n",
        "\n",
        "for _, row in comparison_df.iterrows():\n",
        "    print(f\"{row['Dataset']:<30} {row['Samples']:>12,} {row['MAE']:>10.2f} {row['R²']:>10.4f} {row['Avg Disparity']:>15.2f}\")\n",
        "\n",
        "print(\"-\" * 100)\n",
        "\n",
        "best_accuracy = comparison_df.loc[comparison_df['MAE'].idxmin(), 'Dataset']\n",
        "best_fairness = comparison_df.loc[comparison_df['Avg Disparity'].idxmin(), 'Dataset']\n",
        "\n",
        "print(f\"\\nBest Accuracy: {best_accuracy} (MAE = {comparison_df['MAE'].min():.2f})\")\n",
        "print(f\"Best Fairness: {best_fairness} (Avg Disparity = {comparison_df['Avg Disparity'].min():.2f})\")\n",
        "\n",
        "table_path = OUTPUT_DIR / 'table2_dataset_comparison.csv'\n",
        "comparison_df.to_csv(table_path, index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "display_names = {\n",
        "    'Original (414K)': 'Original\\n(414K)',\n",
        "    'Balanced Fully (44K)': 'Even BMI Categories\\nvia Undersampling (44K)',\n",
        "    'Even BMI Categories (100K)': 'Even BMI Categories\\nvia Oversampling (100K)'\n",
        "}\n",
        "\n",
        "dataset_names = list(results.keys())\n",
        "display_labels = [display_names.get(name, name) for name in dataset_names]\n",
        "colors = get_colors(3)\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# R^2 Comparison (bar chart)\n",
        "ax1 = axes[0]\n",
        "r2_values = [results[name]['r2'] for name in dataset_names]\n",
        "bars1 = ax1.bar(display_labels, r2_values, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
        "ax1.set_ylabel('R² Score', fontweight='bold', fontsize=11)\n",
        "ax1.set_title('R² Score by Dataset', fontweight='bold', fontsize=13)\n",
        "ax1.tick_params(axis='x', rotation=0)\n",
        "ax1.grid(True, alpha=0.3, axis='y')\n",
        "for bar, val in zip(bars1, r2_values):\n",
        "    ax1.text(bar.get_x() + bar.get_width()/2., bar.get_height(), \n",
        "             f'{val:.4f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "# MAE Comparison (bar chart)\n",
        "ax2 = axes[1]\n",
        "mae_values = [results[name]['mae'] for name in dataset_names]\n",
        "bars2 = ax2.bar(display_labels, mae_values, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
        "ax2.set_ylabel('MAE (BMI points)', fontweight='bold', fontsize=11)\n",
        "ax2.set_title('MAE by Dataset (Lower is Better)', fontweight='bold', fontsize=13)\n",
        "ax2.tick_params(axis='x', rotation=0)\n",
        "ax2.grid(True, alpha=0.3, axis='y')\n",
        "for bar, val in zip(bars2, mae_values):\n",
        "    ax2.text(bar.get_x() + bar.get_width()/2., bar.get_height(), \n",
        "             f'{val:.2f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "# Disparity Comparison (bar chart)\n",
        "ax3 = axes[2]\n",
        "disp_values = [results[name]['avg_disparity'] for name in dataset_names]\n",
        "bars3 = ax3.bar(display_labels, disp_values, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
        "ax3.set_ylabel('Avg Disparity (BMI points)', fontweight='bold', fontsize=11)\n",
        "ax3.set_title('Average Disparity by Dataset (Lower is Fairer)', fontweight='bold', fontsize=13)\n",
        "ax3.tick_params(axis='x', rotation=0) \n",
        "ax3.grid(True, alpha=0.3, axis='y')\n",
        "for bar, val in zip(bars3, disp_values):\n",
        "    ax3.text(bar.get_x() + bar.get_width()/2., bar.get_height(), \n",
        "             f'{val:.2f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "save_figure(fig, 'dataset_comparison.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "data_selected = data_balanced_100k.copy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 4: Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use the selected 100K dataset from Section 3\n",
        "X = data_selected[FEATURE_COLS].copy()\n",
        "y = data_selected['BMI'].copy()\n",
        "y_cat = y.apply(get_bmi_category_numeric)\n",
        "\n",
        "print(f\"Dataset: {len(data_selected):,} samples\")\n",
        "print(f\"Features: {len(FEATURE_COLS)}\")\n",
        "print(f\"BMI range: {y.min():.1f} - {y.max():.1f}\")\n",
        "\n",
        "# Train/Test Split FIRST (to prevent data leakage)\n",
        "print(\"\\n[4.1b] Splitting data (80/20, stratified by BMI category)...\")\n",
        "X_train_fs, X_test_fs, y_train_fs, y_test_fs = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y_cat\n",
        ")\n",
        "\n",
        "print(f\"Training set: {len(X_train_fs):,} samples (80%)\")\n",
        "print(f\"Test set: {len(X_test_fs):,} samples (20%)\")\n",
        "\n",
        "# Imputation (fit on train only)\n",
        "print(\"\\n[4.1c] Imputing missing values...\")\n",
        "imputer_fs = SimpleImputer(strategy='median')\n",
        "X_train_imp = pd.DataFrame(\n",
        "    imputer_fs.fit_transform(X_train_fs),\n",
        "    columns=FEATURE_COLS,\n",
        "    index=X_train_fs.index\n",
        ")\n",
        "X_test_imp = pd.DataFrame(\n",
        "    imputer_fs.transform(X_test_fs),\n",
        "    columns=FEATURE_COLS,\n",
        "    index=X_test_fs.index\n",
        ")\n",
        "print(f\"Missing values before: {X_train_fs.isnull().sum().sum():,}\")\n",
        "print(f\"Missing values after: {X_train_imp.isnull().sum().sum()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# METHOD 1: Correlation (Training data only)\n",
        "corr_scores = {}\n",
        "for col in FEATURE_COLS:\n",
        "    corr = np.abs(np.corrcoef(X_train_imp[col], y_train_fs)[0, 1])\n",
        "    corr_scores[col] = corr if not np.isnan(corr) else 0\n",
        "print(f\"Correlation calculated on {len(X_train_imp):,} training samples\")\n",
        "\n",
        "# METHOD 2: Mutual Information (Training data only)\n",
        "mi_scores = mutual_info_regression(X_train_imp, y_train_fs, random_state=42)\n",
        "mi_dict = dict(zip(FEATURE_COLS, mi_scores))\n",
        "print(f\"MI calculated on {len(X_train_imp):,} training samples\")\n",
        "\n",
        "# METHOD 3: Random Forest Importance (Training data only)\n",
        "rf_fs = RandomForestRegressor(n_estimators=100, max_depth=15, random_state=42, n_jobs=-1)\n",
        "rf_fs.fit(X_train_imp, y_train_fs)\n",
        "rf_dict = dict(zip(FEATURE_COLS, rf_fs.feature_importances_))\n",
        "print(f\"RF trained on {len(X_train_imp):,} training samples\")\n",
        "\n",
        "# METHOD 4: Permutation Importance (Test data)\n",
        "perm_result = permutation_importance(rf_fs, X_test_imp, y_test_fs, n_repeats=10, random_state=42, n_jobs=-1)\n",
        "perm_dict = dict(zip(FEATURE_COLS, perm_result.importances_mean))\n",
        "print(f\"Permutation importance calculated on {len(X_test_imp):,} test samples\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_results = []\n",
        "for col in FEATURE_COLS:\n",
        "    feature_results.append({\n",
        "        'Feature': col,\n",
        "        'Description': FEATURE_NAMES.get(col, col),\n",
        "        'Corr': corr_scores[col],\n",
        "        'MI': mi_dict[col],\n",
        "        'RF': rf_dict[col],\n",
        "        'Perm': perm_dict[col]\n",
        "    })\n",
        "\n",
        "importance_df = pd.DataFrame(feature_results)\n",
        "\n",
        "# Normalize each metric to [0, 1] scale\n",
        "for metric in ['Corr', 'MI', 'RF', 'Perm']:\n",
        "    min_val = importance_df[metric].min()\n",
        "    max_val = importance_df[metric].max()\n",
        "    if max_val > min_val:\n",
        "        importance_df[metric + '_Norm'] = (importance_df[metric] - min_val) / (max_val - min_val)\n",
        "    else:\n",
        "        importance_df[metric + '_Norm'] = 0\n",
        "\n",
        "# Combined score = average of normalized Corr, MI, RF (excluding Perm for combined)\n",
        "importance_df['Combined'] = importance_df[['Corr_Norm', 'MI_Norm', 'RF_Norm']].mean(axis=1)\n",
        "\n",
        "# Sort by Combined score\n",
        "importance_df = importance_df.sort_values('Combined', ascending=False).reset_index(drop=True)\n",
        "importance_df['Rank'] = range(1, len(importance_df) + 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "table3_df = importance_df[['Rank', 'Feature', 'Description', 'Corr', 'MI', 'RF', 'Combined']].copy()\n",
        "table3_df = table3_df.round({'Corr': 4, 'MI': 4, 'RF': 4, 'Combined': 3})\n",
        "\n",
        "print(\"\\n\" + \"=\" * 100)\n",
        "print(\"TABLE 3: COMBINED FEATURE IMPORTANCE (All 16 Features)\")\n",
        "print(\"=\" * 100)\n",
        "print(f\"\\n{'Rank':<6} {'Feature':<12} {'Description':<25} {'Corr':>8} {'MI':>8} {'RF':>8} {'Combined':>10}\")\n",
        "print(\"-\" * 100)\n",
        "\n",
        "for _, row in table3_df.iterrows():\n",
        "    print(f\"{int(row['Rank']):<6} {row['Feature']:<12} {row['Description']:<25} \"\n",
        "          f\"{row['Corr']:>8.4f} {row['MI']:>8.4f} {row['RF']:>8.4f} {row['Combined']:>10.3f}\")\n",
        "\n",
        "print(\"-\" * 100)\n",
        "\n",
        "# Save to CSV\n",
        "table3_path = FEATURE_DIR / 'table3_combined_feature_importance.csv'\n",
        "table3_df.to_csv(table3_path, index=False)\n",
        "print(f\"\\nTable 3 saved to: {table3_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sort by Permutation importance for Table 4\n",
        "table4_df = importance_df[['Feature', 'Description', 'Perm']].copy()\n",
        "table4_df = table4_df.sort_values('Perm', ascending=False).reset_index(drop=True)\n",
        "table4_df['Rank'] = range(1, len(table4_df) + 1)\n",
        "table4_df = table4_df[['Rank', 'Feature', 'Description', 'Perm']]\n",
        "table4_df = table4_df.round({'Perm': 4})\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"TABLE 4: PERMUTATION FEATURE IMPORTANCE (All 16 Features)\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\n{'Rank':<6} {'Feature':<12} {'Description':<30} {'Permutation':>12}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for _, row in table4_df.iterrows():\n",
        "    print(f\"{int(row['Rank']):<6} {row['Feature']:<12} {row['Description']:<30} {row['Perm']:>12.4f}\")\n",
        "\n",
        "print(\"-\" * 80)\n",
        "\n",
        "table4_path = FEATURE_DIR / 'table4_permutation_feature_importance.csv'\n",
        "table4_df.to_csv(table4_path, index=False)\n",
        "print(f\"\\nTable saved to: {table4_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate correlation matrix for selected features + BMI\n",
        "corr_features = FEATURE_COLS + ['BMI']\n",
        "corr_data = data_selected[corr_features].copy()\n",
        "\n",
        "# Impute missing values for correlation calculation\n",
        "imputer_corr = SimpleImputer(strategy='median')\n",
        "corr_data_imp = pd.DataFrame(\n",
        "    imputer_corr.fit_transform(corr_data),\n",
        "    columns=corr_features\n",
        ")\n",
        "\n",
        "# Calculate correlation matrix\n",
        "corr_matrix = corr_data_imp.corr()\n",
        "\n",
        "# Create heatmap\n",
        "fig, ax = plt.subplots(figsize=(14, 12))\n",
        "\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "purple_colors = ['#f5f0ff', '#d0c2f5', '#a88de6', '#7a4ec7', '#5d33ab', '#3c1e7f']\n",
        "purple_cmap = LinearSegmentedColormap.from_list('purple_palette', purple_colors, N=256)\n",
        "\n",
        "sns.heatmap(\n",
        "    corr_matrix,\n",
        "    annot=True,\n",
        "    fmt='.2f',\n",
        "    cmap=purple_cmap,\n",
        "    vmin=-1,\n",
        "    vmax=1,\n",
        "    square=True,\n",
        "    linewidths=0.5,\n",
        "    ax=ax,\n",
        "    annot_kws={'size': 8, 'color': 'black'},\n",
        "    cbar_kws={'shrink': 0.8}\n",
        ")\n",
        "\n",
        "ax.set_title('Correlation Matrix: 16 Selected Features + BMI', fontsize=14, fontweight='bold', pad=20)\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right', fontsize=9)\n",
        "ax.set_yticklabels(ax.get_yticklabels(), rotation=0, fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "save_figure(fig, 'balanced_dataset_correlation_heatmap.png', dpi=300)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sort by Combined importance for plotting\n",
        "plot_df = importance_df.sort_values('Combined', ascending=True)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "# Create horizontal bar chart\n",
        "colors_bar = get_colors(len(plot_df))\n",
        "bars = ax.barh(\n",
        "    range(len(plot_df)), \n",
        "    plot_df['Combined'], \n",
        "    color=colors_bar[0], \n",
        "    alpha=0.8, \n",
        "    edgecolor='black',\n",
        "    linewidth=1\n",
        ")\n",
        "\n",
        "ax.set_yticks(range(len(plot_df)))\n",
        "ax.set_yticklabels([f\"{row['Feature']} ({row['Description']})\" \n",
        "                    for _, row in plot_df.iterrows()], fontsize=9)\n",
        "\n",
        "for i, (idx, row) in enumerate(plot_df.iterrows()):\n",
        "    ax.text(row['Combined'] + 0.01, i, f\"{row['Combined']:.3f}\", \n",
        "            va='center', fontsize=9, fontweight='bold')\n",
        "\n",
        "ax.set_xlabel('Combined Importance Score', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Feature Importance Rankings (Combined Score)', fontsize=14, fontweight='bold')\n",
        "ax.grid(True, alpha=0.3, axis='x')\n",
        "ax.set_xlim(0, plot_df['Combined'].max() * 1.15)\n",
        "\n",
        "plt.tight_layout()\n",
        "save_figure(fig, 'feature_importance_bar.png', dpi=300)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 5: Model Training & Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use the selected 100K dataset from Section 3\n",
        "X = data_selected[FEATURE_COLS].copy()\n",
        "y_bmi = data_selected['BMI'].copy()\n",
        "y_category = data_selected['BMI_Category'].copy()\n",
        "y_obesity = (y_bmi >= 30).astype(int)\n",
        "y_cat_numeric = y_bmi.apply(get_bmi_category_numeric)\n",
        "\n",
        "print(f\"Dataset: {len(data_selected):,} samples\")\n",
        "print(f\"Features: {len(FEATURE_COLS)}\")\n",
        "print(f\"Obesity rate: {y_obesity.mean():.1%}\")\n",
        "\n",
        "# Train/Test Split (stratified by BMI category)\n",
        "X_train, X_test, y_train, y_test, y_cat_train, y_cat_test, y_obs_train, y_obs_test = train_test_split(\n",
        "    X, y_bmi, y_category, y_obesity,\n",
        "    test_size=0.2, random_state=42, stratify=y_cat_numeric\n",
        ")\n",
        "\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_train_imp = pd.DataFrame(imputer.fit_transform(X_train), columns=FEATURE_COLS, index=X_train.index)\n",
        "X_test_imp = pd.DataFrame(imputer.transform(X_test), columns=FEATURE_COLS, index=X_test.index)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train_imp), columns=FEATURE_COLS, index=X_train.index)\n",
        "X_test_scaled = pd.DataFrame(scaler.transform(X_test_imp), columns=FEATURE_COLS, index=X_test.index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models = {}\n",
        "\n",
        "# Ridge Regression\n",
        "ridge = Ridge(alpha=0.1, random_state=42)\n",
        "ridge.fit(X_train_scaled, y_train)\n",
        "models['Ridge Regression'] = ridge\n",
        "print(\"Ridge trained\")\n",
        "\n",
        "# Lasso Regression\n",
        "lasso = Lasso(alpha=0.01, random_state=42, max_iter=5000)\n",
        "lasso.fit(X_train_scaled, y_train)\n",
        "models['Lasso Regression'] = lasso\n",
        "print(\"Lasso trained\")\n",
        "\n",
        "# Decision Tree\n",
        "dt = DecisionTreeRegressor(max_depth=15, random_state=42)\n",
        "dt.fit(X_train_scaled, y_train)\n",
        "models['Decision Tree'] = dt\n",
        "print(\"Decision Tree trained\")\n",
        "\n",
        "# Random Forest\n",
        "rf = RandomForestRegressor(n_estimators=100, max_depth=15, random_state=42, n_jobs=-1)\n",
        "rf.fit(X_train_scaled, y_train)\n",
        "models['Random Forest'] = rf\n",
        "print(\"Random Forest trained\")\n",
        "\n",
        "# Gradient Boosting\n",
        "gb = GradientBoostingRegressor(n_estimators=100, learning_rate=0.08, max_depth=10, random_state=42)\n",
        "gb.fit(X_train_scaled, y_train)\n",
        "models['Gradient Boosting'] = gb\n",
        "print(\"Gradient Boosting trained\")\n",
        "\n",
        "# Voting Ensemble\n",
        "voting = VotingRegressor(estimators=[\n",
        "    ('ridge', Ridge(alpha=0.1, random_state=42)),\n",
        "    ('rf', RandomForestRegressor(n_estimators=100, max_depth=15, random_state=42, n_jobs=-1)),\n",
        "    ('gb', GradientBoostingRegressor(n_estimators=100, learning_rate=0.08, max_depth=10, random_state=42))\n",
        "])\n",
        "voting.fit(X_train_scaled, y_train)\n",
        "models['Voting Ensemble'] = voting\n",
        "print(\"Voting Ensemble trained\")\n",
        "\n",
        "# Stacking Ensemble\n",
        "stacking = StackingRegressor(\n",
        "    estimators=[\n",
        "        ('ridge', Ridge(alpha=0.1, random_state=42)),\n",
        "        ('rf', RandomForestRegressor(n_estimators=100, max_depth=15, random_state=42, n_jobs=-1)),\n",
        "        ('gb', GradientBoostingRegressor(n_estimators=100, learning_rate=0.08, max_depth=10, random_state=42))\n",
        "    ],\n",
        "    final_estimator=Ridge(alpha=0.1),\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "stacking.fit(X_train_scaled, y_train)\n",
        "models['Stacking Ensemble'] = stacking\n",
        "print(\"Stacking Ensemble trained\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "regression_results = []\n",
        "\n",
        "for name, model in models.items():\n",
        "\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    \n",
        "    regression_results.append({\n",
        "        'Model': name,\n",
        "        'RMSE': rmse,\n",
        "        'MAE': mae,\n",
        "        'R2': r2\n",
        "    })\n",
        "    \n",
        "    print(f\"  {name}: RMSE={rmse:.2f}, MAE={mae:.2f}, R²={r2:.4f}\")\n",
        "\n",
        "# Add Baseline\n",
        "y_mean = np.full_like(y_test, y_train.mean())\n",
        "baseline_rmse = np.sqrt(mean_squared_error(y_test, y_mean))\n",
        "baseline_mae = mean_absolute_error(y_test, y_mean)\n",
        "baseline_r2 = 0.0 \n",
        "\n",
        "regression_results.append({\n",
        "    'Model': 'Mean Baseline',\n",
        "    'RMSE': baseline_rmse,\n",
        "    'MAE': baseline_mae,\n",
        "    'R2': baseline_r2\n",
        "})\n",
        "print(f\"  Mean Baseline: RMSE={baseline_rmse:.2f}, MAE={baseline_mae:.2f}, R²={baseline_r2:.4f}\")\n",
        "\n",
        "regression_df = pd.DataFrame(regression_results)\n",
        "regression_df = regression_df.sort_values('R2', ascending=False).reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"TABLE 5: REGRESSION-BASED BMI PREDICTION METRICS\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\n{'Model':<25} {'RMSE':>10} {'MAE':>10} {'R²':>10}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "for _, row in regression_df.iterrows():\n",
        "    print(f\"{row['Model']:<25} {row['RMSE']:>10.2f} {row['MAE']:>10.2f} {row['R2']:>10.4f}\")\n",
        "\n",
        "print(\"-\" * 70)\n",
        "\n",
        "best_model = regression_df.iloc[0]\n",
        "print(f\"\\nBest Model: {best_model['Model']} (R^2 = {best_model['R2']:.4f})\")\n",
        "\n",
        "table5_path = OUTPUT_DIR / 'table5_regression_metrics.csv'\n",
        "regression_df.to_csv(table5_path, index=False)\n",
        "print(f\"\\nTable saved to: {table5_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_df = regression_df[regression_df['Model'] != 'Mean Baseline'].copy()\n",
        "plot_df = plot_df.sort_values('R2', ascending=True)\n",
        "model_names = plot_df['Model'].tolist()\n",
        "colors = get_colors(len(model_names))\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "# R^2 Score\n",
        "ax1 = axes[0]\n",
        "bars1 = ax1.barh(model_names, plot_df['R2'], color=colors, alpha=0.8, edgecolor='black', linewidth=1)\n",
        "ax1.set_xlabel('R² Score', fontweight='bold', fontsize=11)\n",
        "ax1.set_title('R² Score by Model (Higher is Better)', fontweight='bold', fontsize=12)\n",
        "ax1.grid(True, alpha=0.3, axis='x')\n",
        "for i, (bar, val) in enumerate(zip(bars1, plot_df['R2'])):\n",
        "    ax1.text(val + 0.01, bar.get_y() + bar.get_height()/2, f'{val:.4f}', \n",
        "             va='center', fontsize=9, fontweight='bold')\n",
        "\n",
        "# MAE\n",
        "ax2 = axes[1]\n",
        "bars2 = ax2.barh(model_names, plot_df['MAE'], color=colors, alpha=0.8, edgecolor='black', linewidth=1)\n",
        "ax2.set_xlabel('MAE (BMI points)', fontweight='bold', fontsize=11)\n",
        "ax2.set_title('MAE by Model (Lower is Better)', fontweight='bold', fontsize=12)\n",
        "ax2.grid(True, alpha=0.3, axis='x')\n",
        "for i, (bar, val) in enumerate(zip(bars2, plot_df['MAE'])):\n",
        "    ax2.text(val + 0.05, bar.get_y() + bar.get_height()/2, f'{val:.2f}', \n",
        "             va='center', fontsize=9, fontweight='bold')\n",
        "\n",
        "# RMSE\n",
        "ax3 = axes[2]\n",
        "bars3 = ax3.barh(model_names, plot_df['RMSE'], color=colors, alpha=0.8, edgecolor='black', linewidth=1)\n",
        "ax3.set_xlabel('RMSE (BMI points)', fontweight='bold', fontsize=11)\n",
        "ax3.set_title('RMSE by Model (Lower is Better)', fontweight='bold', fontsize=12)\n",
        "ax3.grid(True, alpha=0.3, axis='x')\n",
        "for i, (bar, val) in enumerate(zip(bars3, plot_df['RMSE'])):\n",
        "    ax3.text(val + 0.05, bar.get_y() + bar.get_height()/2, f'{val:.2f}', \n",
        "             va='center', fontsize=9, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "save_figure(fig, 'model_regression_comparison.png', dpi=300)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_predictions = {}\n",
        "for name, model in models.items():\n",
        "    model_predictions[name] = model.predict(X_test_scaled)\n",
        "\n",
        "# Store the best model (Stacking Ensemble) predictions separately\n",
        "best_model_name = regression_df.iloc[0]['Model']\n",
        "y_pred_best = model_predictions[best_model_name]\n",
        "\n",
        "# Create predicted categories for classification metrics\n",
        "def bmi_to_category_name(bmi):\n",
        "    if bmi < 18.5: return 'Underweight'\n",
        "    elif bmi < 25: return 'Normal'\n",
        "    elif bmi < 30: return 'Overweight'\n",
        "    elif bmi < 35: return 'Obese Class I'\n",
        "    elif bmi < 40: return 'Obese Class II'\n",
        "    else: return 'Obese Class III'\n",
        "\n",
        "y_pred_categories = pd.Series([bmi_to_category_name(bmi) for bmi in y_pred_best], index=y_test.index)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 6: Classification & Risk Estimation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def bmi_to_risk_interpolated(bmi):\n",
        "\n",
        "    if bmi < 18.5:\n",
        "        risk = 0.10 + 0.05 * max(0, (18.5 - bmi) / 3.5)\n",
        "    elif bmi < 25:\n",
        "        distance_from_ideal = abs(bmi - 22)\n",
        "        risk = 0.10 + 0.10 * (distance_from_ideal / 3)\n",
        "    elif bmi < 30:\n",
        "        position = (bmi - 25) / 5\n",
        "        risk = 0.30 + 0.20 * position\n",
        "    elif bmi < 35:\n",
        "        position = (bmi - 30) / 5\n",
        "        risk = 0.60 + 0.20 * position\n",
        "    elif bmi < 40:\n",
        "        position = (bmi - 35) / 5\n",
        "        risk = 0.80 + 0.12 * position\n",
        "    else:\n",
        "        excess = min((bmi - 40) / 10, 1)\n",
        "        risk = 0.92 + 0.07 * excess\n",
        "    return np.clip(risk, 0, 1)\n",
        "\n",
        "CATEGORY_ORDER = ['Underweight', 'Normal', 'Overweight', 'Obese Class I', 'Obese Class II', 'Obese Class III']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classification_results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "\n",
        "    y_bmi_pred = model_predictions[name]\n",
        "    y_category_pred = pd.Series([bmi_to_category_name(bmi) for bmi in y_bmi_pred])\n",
        "    y_risk_proba = np.array([bmi_to_risk_interpolated(bmi) for bmi in y_bmi_pred])\n",
        "    y_obesity_pred = (y_bmi_pred >= 30).astype(int)\n",
        "    \n",
        "    accuracy = accuracy_score(y_obs_test, y_obesity_pred)\n",
        "    precision = precision_score(y_obs_test, y_obesity_pred, zero_division=0)\n",
        "    recall = recall_score(y_obs_test, y_obesity_pred, zero_division=0)\n",
        "    f1 = f1_score(y_obs_test, y_obesity_pred, zero_division=0)\n",
        "    auc_roc = roc_auc_score(y_obs_test, y_risk_proba)\n",
        "    brier = brier_score_loss(y_obs_test, y_risk_proba)\n",
        "    \n",
        "    category_accuracy = accuracy_score(y_cat_test, y_category_pred)\n",
        "    actual_cat_idx = [CATEGORY_ORDER.index(cat) for cat in y_cat_test]\n",
        "    pred_cat_idx = [CATEGORY_ORDER.index(cat) for cat in y_category_pred]\n",
        "    within_1_category = (np.abs(np.array(actual_cat_idx) - np.array(pred_cat_idx)) <= 1).mean()\n",
        "    \n",
        "    bmi_tolerance_2 = (np.abs(y_bmi_pred - y_test.values) <= 2.0).mean()\n",
        "    bmi_tolerance_3 = (np.abs(y_bmi_pred - y_test.values) <= 3.0).mean()\n",
        "    \n",
        "    classification_results[name] = {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'auc_roc': auc_roc,\n",
        "        'brier': brier,\n",
        "        'category_accuracy': category_accuracy,\n",
        "        'within_1_category': within_1_category,\n",
        "        'bmi_tolerance_2': bmi_tolerance_2,\n",
        "        'bmi_tolerance_3': bmi_tolerance_3,\n",
        "        'y_risk_proba': y_risk_proba,\n",
        "        'y_obesity_pred': y_obesity_pred\n",
        "    }\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "table6_data = []\n",
        "for name, res in classification_results.items():\n",
        "    table6_data.append({\n",
        "        'Model': name,\n",
        "        'Accuracy': res['accuracy'],\n",
        "        'Precision': res['precision'],\n",
        "        'Recall': res['recall'],\n",
        "        'F1': res['f1'],\n",
        "        'AUC-ROC': res['auc_roc']\n",
        "    })\n",
        "\n",
        "table6_df = pd.DataFrame(table6_data)\n",
        "table6_df = table6_df.sort_values('AUC-ROC', ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 90)\n",
        "print(\"TABLE 6: BINARY OBESITY CLASSIFICATION (BMI ≥ 30)\")\n",
        "print(\"=\" * 90)\n",
        "print(f\"\\n{'Model':<25} {'Accuracy':>10} {'Precision':>10} {'Recall':>10} {'F1':>10} {'AUC-ROC':>10}\")\n",
        "print(\"-\" * 90)\n",
        "\n",
        "for _, row in table6_df.iterrows():\n",
        "    print(f\"{row['Model']:<25} {row['Accuracy']:>10.4f} {row['Precision']:>10.4f} \"\n",
        "          f\"{row['Recall']:>10.4f} {row['F1']:>10.4f} {row['AUC-ROC']:>10.4f}\")\n",
        "\n",
        "print(\"-\" * 90)\n",
        "\n",
        "# Best model\n",
        "best_auc = table6_df.iloc[0]\n",
        "print(f\"\\nBest AUC-ROC: {best_auc['Model']} ({best_auc['AUC-ROC']:.4f})\")\n",
        "\n",
        "table6_path = OUTPUT_DIR / 'table6_binary_classification.csv'\n",
        "table6_df.to_csv(table6_path, index=False)\n",
        "print(f\"\\nTable saved to: {table6_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "table7_data = []\n",
        "for name, res in classification_results.items():\n",
        "    table7_data.append({\n",
        "        'Model': name,\n",
        "        'Category Acc': res['category_accuracy'],\n",
        "        'Within-1-Cat': res['within_1_category'],\n",
        "        '±2 BMI': res['bmi_tolerance_2'],\n",
        "        '±3 BMI': res['bmi_tolerance_3'],\n",
        "        'Brier Score': res['brier']\n",
        "    })\n",
        "\n",
        "table7_df = pd.DataFrame(table7_data)\n",
        "table7_df = table7_df.sort_values('Brier Score', ascending=True).reset_index(drop=True)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 90)\n",
        "print(\"TABLE 7: RISK ESTIMATION & CATEGORY PREDICTION\")\n",
        "print(\"=\" * 90)\n",
        "print(f\"\\n{'Model':<25} {'Cat-Acc':>10} {'±1-Cat':>10} {'±2 BMI':>10} {'±3 BMI':>10} {'Brier':>10}\")\n",
        "print(\"-\" * 90)\n",
        "\n",
        "for _, row in table7_df.iterrows():\n",
        "    print(f\"{row['Model']:<25} {row['Category Acc']:>10.4f} {row['Within-1-Cat']:>10.4f} \"\n",
        "          f\"{row['±2 BMI']:>10.4f} {row['±3 BMI']:>10.4f} {row['Brier Score']:>10.4f}\")\n",
        "\n",
        "print(\"-\" * 90)\n",
        "# Best model\n",
        "best_brier = table7_df.iloc[0]\n",
        "print(f\"\\nBest Brier Score: {best_brier['Model']} ({best_brier['Brier Score']:.4f})\")\n",
        "\n",
        "table7_path = OUTPUT_DIR / 'table7_risk_estimation.csv'\n",
        "table7_df.to_csv(table7_path, index=False)\n",
        "print(f\"\\nTable saved to: {table7_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1', 'AUC-ROC']\n",
        "model_names = list(classification_results.keys())\n",
        "\n",
        "# Create radar chart data\n",
        "radar_data = pd.DataFrame({\n",
        "    name: [classification_results[name]['accuracy'], \n",
        "           classification_results[name]['precision'],\n",
        "           classification_results[name]['recall'], \n",
        "           classification_results[name]['f1'], \n",
        "           classification_results[name]['auc_roc']]\n",
        "    for name in model_names\n",
        "}, index=metrics)\n",
        "\n",
        "num_vars = len(metrics)\n",
        "angles = [n / float(num_vars) * 2 * np.pi for n in range(num_vars)]\n",
        "angles += angles[:1]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(polar=True))\n",
        "colors = get_colors(len(model_names))\n",
        "\n",
        "for i, name in enumerate(model_names):\n",
        "    values = radar_data[name].tolist()\n",
        "    values += values[:1]\n",
        "    \n",
        "    ax.plot(angles, values, 'o-', linewidth=2, label=name, color=colors[i % len(colors)])\n",
        "    ax.fill(angles, values, alpha=0.1, color=colors[i % len(colors)])\n",
        "ax.set_theta_offset(np.pi / 2)\n",
        "ax.set_theta_direction(-1)\n",
        "ax.set_xticks(angles[:-1])\n",
        "ax.set_xticklabels(metrics, fontsize=11, fontweight='bold')\n",
        "ax.set_ylim(0, 1)\n",
        "ax.set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])\n",
        "ax.set_yticklabels(['0.2', '0.4', '0.6', '0.8', '1.0'], fontsize=9)\n",
        "ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0), fontsize=9)\n",
        "\n",
        "ax.set_title('Model Performance Comparison\\n(Binary Obesity Classification)', \n",
        "             fontsize=14, fontweight='bold', y=1.08)\n",
        "\n",
        "plt.tight_layout()\n",
        "save_figure(fig, 'model_performance_radar.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nRadar chart saved\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 7: Fairness Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "demographic_groups = {\n",
        "    '_SEX': {\n",
        "        1: 'Male',\n",
        "        2: 'Female'\n",
        "    },\n",
        "    '_AGEG5YR': {\n",
        "        'Young Adult (18-39)': lambda x: x <= 5,\n",
        "        'Middle Age (40-59)': lambda x: (x > 5) & (x <= 9),\n",
        "        'Senior (60+)': lambda x: x > 9\n",
        "    },\n",
        "    '_RACE': {\n",
        "        'White': lambda x: x == 1,\n",
        "        'Black': lambda x: x == 2,\n",
        "        'Asian': lambda x: x == 4,\n",
        "        'Hispanic': lambda x: x == 8,\n",
        "        'Other': lambda x: (x != 1) & (x != 2) & (x != 4) & (x != 8)\n",
        "    },\n",
        "    '_INCOMG1': {\n",
        "        'Low Income (<$25k)': lambda x: x <= 2,\n",
        "        'Middle Income ($25-75k)': lambda x: (x > 2) & (x <= 5),\n",
        "        'High Income ($75k+)': lambda x: x > 5\n",
        "    }\n",
        "}\n",
        "\n",
        "best_bmi_pred = model_predictions[best_model_name]\n",
        "best_obesity_pred = (best_bmi_pred >= 30).astype(int)\n",
        "best_risk_proba = np.array([bmi_to_risk_interpolated(bmi) for bmi in best_bmi_pred])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fairness_results = defaultdict(dict)\n",
        "X_test_orig = X_test_imp.copy()\n",
        "\n",
        "for sex_code, sex_name in demographic_groups['_SEX'].items():\n",
        "    mask = X_test_orig['_SEX'] == sex_code\n",
        "    if mask.sum() == 0:\n",
        "        continue\n",
        "    \n",
        "    n = mask.sum()\n",
        "    mae = mean_absolute_error(y_test[mask], best_bmi_pred[mask])\n",
        "    acc = accuracy_score(y_obs_test[mask], best_obesity_pred[mask])\n",
        "    prec = precision_score(y_obs_test[mask], best_obesity_pred[mask], zero_division=0)\n",
        "    rec = recall_score(y_obs_test[mask], best_obesity_pred[mask], zero_division=0)\n",
        "    auc = roc_auc_score(y_obs_test[mask], best_risk_proba[mask])\n",
        "    \n",
        "    fairness_results['SEX'][sex_name] = {\n",
        "        'n': n, 'mae': mae, 'accuracy': acc, 'precision': prec, 'recall': rec, 'auc_roc': auc\n",
        "    }\n",
        "\n",
        "for age_name, age_func in demographic_groups['_AGEG5YR'].items():\n",
        "    mask = age_func(X_test_orig['_AGEG5YR'])\n",
        "    if mask.sum() == 0:\n",
        "        continue\n",
        "    \n",
        "    n = mask.sum()\n",
        "    mae = mean_absolute_error(y_test[mask], best_bmi_pred[mask])\n",
        "    acc = accuracy_score(y_obs_test[mask], best_obesity_pred[mask])\n",
        "    prec = precision_score(y_obs_test[mask], best_obesity_pred[mask], zero_division=0)\n",
        "    rec = recall_score(y_obs_test[mask], best_obesity_pred[mask], zero_division=0)\n",
        "    auc = roc_auc_score(y_obs_test[mask], best_risk_proba[mask])\n",
        "    \n",
        "    fairness_results['AGE'][age_name] = {\n",
        "        'n': n, 'mae': mae, 'accuracy': acc, 'precision': prec, 'recall': rec, 'auc_roc': auc\n",
        "    }\n",
        "\n",
        "for race_name, race_func in demographic_groups['_RACE'].items():\n",
        "    mask = race_func(X_test_orig['_RACE'])\n",
        "    if mask.sum() < 100: \n",
        "        continue\n",
        "    \n",
        "    n = mask.sum()\n",
        "    mae = mean_absolute_error(y_test[mask], best_bmi_pred[mask])\n",
        "    acc = accuracy_score(y_obs_test[mask], best_obesity_pred[mask])\n",
        "    prec = precision_score(y_obs_test[mask], best_obesity_pred[mask], zero_division=0)\n",
        "    rec = recall_score(y_obs_test[mask], best_obesity_pred[mask], zero_division=0)\n",
        "    auc = roc_auc_score(y_obs_test[mask], best_risk_proba[mask])\n",
        "    \n",
        "    fairness_results['RACE'][race_name] = {\n",
        "        'n': n, 'mae': mae, 'accuracy': acc, 'precision': prec, 'recall': rec, 'auc_roc': auc\n",
        "    }\n",
        "\n",
        "for income_name, income_func in demographic_groups['_INCOMG1'].items():\n",
        "    mask = income_func(X_test_orig['_INCOMG1'])\n",
        "    if mask.sum() == 0:\n",
        "        continue\n",
        "    \n",
        "    n = mask.sum()\n",
        "    mae = mean_absolute_error(y_test[mask], best_bmi_pred[mask])\n",
        "    acc = accuracy_score(y_obs_test[mask], best_obesity_pred[mask])\n",
        "    prec = precision_score(y_obs_test[mask], best_obesity_pred[mask], zero_division=0)\n",
        "    rec = recall_score(y_obs_test[mask], best_obesity_pred[mask], zero_division=0)\n",
        "    auc = roc_auc_score(y_obs_test[mask], best_risk_proba[mask])\n",
        "    \n",
        "    fairness_results['INCOME'][income_name] = {\n",
        "        'n': n, 'mae': mae, 'accuracy': acc, 'precision': prec, 'recall': rec, 'auc_roc': auc\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "disparity_summary = []\n",
        "\n",
        "for demo_name, demo_results in fairness_results.items():\n",
        "    if len(demo_results) < 2:\n",
        "        continue\n",
        "    \n",
        "    maes = [v['mae'] for v in demo_results.values()]\n",
        "    accs = [v['accuracy'] for v in demo_results.values()]\n",
        "    aucs = [v['auc_roc'] for v in demo_results.values()]\n",
        "    \n",
        "    mae_disparity = max(maes) - min(maes)\n",
        "    acc_disparity = max(accs) - min(accs)\n",
        "    auc_disparity = max(aucs) - min(aucs)\n",
        "    \n",
        "    # Find best and worst groups\n",
        "    best_group = min(demo_results.keys(), key=lambda k: demo_results[k]['mae'])\n",
        "    worst_group = max(demo_results.keys(), key=lambda k: demo_results[k]['mae'])\n",
        "    \n",
        "    disparity_summary.append({\n",
        "        'Demographic': demo_name,\n",
        "        'MAE Disparity': mae_disparity,\n",
        "        'Accuracy Disparity': acc_disparity,\n",
        "        'AUC Disparity': auc_disparity,\n",
        "        'Best Group (MAE)': best_group,\n",
        "        'Worst Group (MAE)': worst_group,\n",
        "        'Best MAE': min(maes),\n",
        "        'Worst MAE': max(maes)\n",
        "    })\n",
        "    \n",
        "    print(f\"\\n  {demo_name}:\")\n",
        "    print(f\"    MAE Range: {min(maes):.2f} - {max(maes):.2f} (Δ = {mae_disparity:.2f})\")\n",
        "    print(f\"    Best: {best_group}, Worst: {worst_group}\")\n",
        "\n",
        "disparity_df = pd.DataFrame(disparity_summary)\n",
        "disparity_df = disparity_df.sort_values('MAE Disparity', ascending=False).reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 100)\n",
        "print(\"TABLE 8: DEMOGRAPHIC DISPARITY ANALYSIS\")\n",
        "print(\"=\" * 100)\n",
        "print(f\"\\n{'Demographic':<12} {'MAE Δ':>10} {'Acc Δ':>10} {'AUC Δ':>10} {'Best Group':<25} {'Worst Group':<25}\")\n",
        "print(\"-\" * 100)\n",
        "\n",
        "for _, row in disparity_df.iterrows():\n",
        "    print(f\"{row['Demographic']:<12} {row['MAE Disparity']:>10.2f} {row['Accuracy Disparity']:>10.4f} \"\n",
        "          f\"{row['AUC Disparity']:>10.4f} {row['Best Group (MAE)']:<25} {row['Worst Group (MAE)']:<25}\")\n",
        "\n",
        "print(\"-\" * 100)\n",
        "\n",
        "primary_bias = disparity_df.iloc[0]\n",
        "print(f\"\\nPRIMARY SOURCE OF BIAS: {primary_bias['Demographic']} (MAE Disparity: {primary_bias['MAE Disparity']:.2f} BMI points)\")\n",
        "\n",
        "table8_path = OUTPUT_DIR / 'table8_demographic_disparity.csv'\n",
        "disparity_df.to_csv(table8_path, index=False)\n",
        "print(f\"\\nTable saved to: {table8_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_fairness = []\n",
        "\n",
        "for name in models.keys():\n",
        "    y_pred = model_predictions[name]\n",
        "    y_obesity_pred_model = (y_pred >= 30).astype(int)\n",
        "\n",
        "    overall_mae = mean_absolute_error(y_test, y_pred)\n",
        "    overall_r2 = regression_df[regression_df['Model'] == name]['R2'].values[0]\n",
        "    \n",
        "    # Calculate income disparity (primary bias source)\n",
        "    income_maes = []\n",
        "    for income_name, income_func in demographic_groups['_INCOMG1'].items():\n",
        "        mask = income_func(X_test_orig['_INCOMG1'])\n",
        "        if mask.sum() > 0:\n",
        "            income_mae = mean_absolute_error(y_test[mask], y_pred[mask])\n",
        "            income_maes.append(income_mae)\n",
        "    \n",
        "    income_disparity = max(income_maes) - min(income_maes) if len(income_maes) >= 2 else 0\n",
        "    \n",
        "    all_disparities = []\n",
        "    for demo_name in ['_SEX', '_AGEG5YR', '_RACE', '_INCOMG1']:\n",
        "        demo_maes = []\n",
        "        if demo_name == '_SEX':\n",
        "            for code, _ in demographic_groups['_SEX'].items():\n",
        "                mask = X_test_orig['_SEX'] == code\n",
        "                if mask.sum() > 0:\n",
        "                    demo_maes.append(mean_absolute_error(y_test[mask], y_pred[mask]))\n",
        "        else:\n",
        "            for _, func in demographic_groups[demo_name].items():\n",
        "                mask = func(X_test_orig[demo_name])\n",
        "                if mask.sum() > 100:\n",
        "                    demo_maes.append(mean_absolute_error(y_test[mask], y_pred[mask]))\n",
        "        \n",
        "        if len(demo_maes) >= 2:\n",
        "            all_disparities.append(max(demo_maes) - min(demo_maes))\n",
        "    \n",
        "    avg_disparity = np.mean(all_disparities) if all_disparities else 0\n",
        "    \n",
        "    model_fairness.append({\n",
        "        'Model': name,\n",
        "        'MAE': overall_mae,\n",
        "        'R2': overall_r2,\n",
        "        'Income Disparity': income_disparity,\n",
        "        'Avg Disparity': avg_disparity\n",
        "    })\n",
        "\n",
        "fairness_trade_off_df = pd.DataFrame(model_fairness)\n",
        "fairness_trade_off_df = fairness_trade_off_df.sort_values('Avg Disparity', ascending=True).reset_index(drop=True)\n",
        "\n",
        "# Print trade-off table\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"ACCURACY-FAIRNESS TRADE-OFF BY MODEL\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\n{'Model':<25} {'MAE':>8} {'R²':>8} {'Inc Δ':>10} {'Avg Δ':>10}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for _, row in fairness_trade_off_df.iterrows():\n",
        "    print(f\"{row['Model']:<25} {row['MAE']:>8.2f} {row['R2']:>8.4f} \"\n",
        "          f\"{row['Income Disparity']:>10.2f} {row['Avg Disparity']:>10.2f}\")\n",
        "\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Find fairest and most accurate models\n",
        "fairest_model = fairness_trade_off_df.iloc[0]['Model']\n",
        "most_accurate = fairness_trade_off_df.sort_values('R2', ascending=False).iloc[0]['Model']\n",
        "print(f\"\\nMost Accurate: {most_accurate}\")\n",
        "print(f\"Fairest Model: {fairest_model}\")\n",
        "\n",
        "tradeoff_path = OUTPUT_DIR / 'accuracy_fairness_tradeoff.csv'\n",
        "fairness_trade_off_df.to_csv(tradeoff_path, index=False)\n",
        "print(f\"\\nTrade-off analysis saved to: {tradeoff_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# MAE Disparity by Demographic\n",
        "ax1 = axes[0]\n",
        "demo_names = disparity_df['Demographic'].tolist()\n",
        "mae_disparities = disparity_df['MAE Disparity'].tolist()\n",
        "colors = get_colors(len(demo_names))\n",
        "bars1 = ax1.bar(demo_names, mae_disparities, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
        "ax1.set_ylabel('MAE Disparity (BMI points)', fontweight='bold', fontsize=11)\n",
        "ax1.set_title('MAE Disparity by Demographic', fontweight='bold', fontsize=12)\n",
        "ax1.tick_params(axis='x', rotation=0)\n",
        "ax1.grid(True, alpha=0.3, axis='y')\n",
        "for bar, val in zip(bars1, mae_disparities):\n",
        "    ax1.text(bar.get_x() + bar.get_width()/2., bar.get_height(), f'{val:.2f}', \n",
        "             ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "# MAE by Income Group (showing primary bias)\n",
        "ax2 = axes[1]\n",
        "if 'INCOME' in fairness_results:\n",
        "    income_groups = list(fairness_results['INCOME'].keys())\n",
        "    income_maes = [fairness_results['INCOME'][g]['mae'] for g in income_groups]\n",
        "    short_names = ['Low\\n(<$25k)', 'Middle\\n($25-75k)', 'High\\n($75k+)']\n",
        "    bars2 = ax2.bar(short_names, income_maes, color=colors[:3], alpha=0.8, edgecolor='black', linewidth=1.5)\n",
        "    ax2.set_ylabel('MAE (BMI points)', fontweight='bold', fontsize=11)\n",
        "    ax2.set_title('MAE by Income Group\\n(Primary Bias Source)', fontweight='bold', fontsize=12)\n",
        "    ax2.grid(True, alpha=0.3, axis='y')\n",
        "    for bar, val in zip(bars2, income_maes):\n",
        "        ax2.text(bar.get_x() + bar.get_width()/2., bar.get_height(), f'{val:.2f}', \n",
        "                 ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "# Accuracy-Fairness Trade-off\n",
        "ax3 = axes[2]\n",
        "for i, (_, row) in enumerate(fairness_trade_off_df.iterrows()):\n",
        "    ax3.scatter(row['MAE'], row['Avg Disparity'], s=200, c=[colors[i % len(colors)]], \n",
        "                alpha=0.8, edgecolors='black', linewidth=1.5, label=row['Model'])\n",
        "    ax3.annotate(row['Model'].split()[0], (row['MAE'], row['Avg Disparity']), \n",
        "                 textcoords=\"offset points\", xytext=(5, 5), fontsize=8)\n",
        "\n",
        "ax3.set_xlabel('MAE (Lower = More Accurate)', fontweight='bold', fontsize=11)\n",
        "ax3.set_ylabel('Avg Disparity (Lower = Fairer)', fontweight='bold', fontsize=11)\n",
        "ax3.set_title('Accuracy-Fairness Trade-off', fontweight='bold', fontsize=12)\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "save_figure(fig, 'fairness_disparity_analysis.png', dpi=300)\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (myenv)",
      "language": "python",
      "name": "myenv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
